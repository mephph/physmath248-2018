{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical derivatives \n",
    "\n",
    "In this section we will learn how we can calculate a derivative numerically. The fundamental idea involves replacing differentials with differences. An important aspect is to think about the types of errors that emerge when doing that, especially we have to introduce the important concepts of rounding error and truncation errors.\n",
    "\n",
    "**Literature:** Numerical Recipies, Ch. 5.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference equations\n",
    "Function\n",
    "$$ y = f(x) $$ for example $$y = x^2$$ for $x \\in [1,5]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab nbagg \n",
    "x=linspace(5,25,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(1)\n",
    "xl =  4; xr = 22\n",
    "f = lambda x: x**2    # function\n",
    "x0 = 15               # take derivative at x0\n",
    "ff = lambda x: 2*x0*x + f(x0) -2*x0**2   # derivative\n",
    "close(1);figure(1)\n",
    "plot(x,f(x)); xlabel('x'), ylabel('f(x)'); ylim(0,500)\n",
    "if True:\n",
    "    plot(x0,f(x0),'o')\n",
    "    plot(x[4:22],ff(x[4:22]),'-.',lw=2)\n",
    "if True:\n",
    "    x1=x[6];x2=x[18]\n",
    "    plot([x1,x2],[ff(x1),ff(x1)],'k--x',lw=1)\n",
    "    plot([x2,x2],[ff(x1),ff(x2)],'k--x',lw=1)\n",
    "    text(0.5*(x2+x1),1.1*ff(x1),'$ \\Delta x$')\n",
    "    text(1.02*x2,0.5*(ff(x1)+ff(x2)),'$ \\Delta y$')\n",
    "    text(x1,0.5*ff(x1),'$x_1$')\n",
    "    text(x2,0.5*ff(x1),'$x_2$')\n",
    "    text(1.02*x2,ff(x1),'$y_1$')\n",
    "    text(1.02*x2,0.9*ff(x2),'$y_2 = ff(x_2)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{\\Delta y}{\\Delta x} = \n",
    "\\frac{y_2 - y_1}{x_2 - x_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative \n",
    "The derivative $\\frac{df}{dx}$ of a function $y=f(x)$ can be approximated by the difference equation \n",
    "$$ f'(x) \\approx \\frac{f(x+h) -f(x)}{h}.$$\n",
    "\n",
    "Why? Rearrange the Taylor expansion of $f(x)$\n",
    "$$\n",
    "f(x+h) = f(x) + hf^\\prime(x) + \\frac{1}{2}h^2f^{\\prime\\prime}(x)\n",
    " + \\frac{1}{6}h^3f^{\\prime\\prime\\prime}(x) + \\dots\n",
    "$$\n",
    "to solve for $f^\\prime(x)$ and discard order two and higher terms\n",
    "$$\n",
    "\\frac{1}{2}h^2f^{\\prime\\prime}(x)\n",
    " + \\frac{1}{6}h^3f^{\\prime\\prime\\prime}(x) + \\dots\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv1(f,x,h):\n",
    "    dfdx = (f(x+h) - f(x)) / h\n",
    "    return dfdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv1(f,1,1.e-3) - 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the answer is not exactly `2.00000000` as we know the answer to be from the analytical approach. But smaller values of `h` give a better answer? _Right?_ well, let's see .... let's analyse the error in a bit more detail. The higher order terms that we discarded represent the truncation error. They represent the difference between the solution of the difference equation and the exact mathematical equation, no matter how _precisely_ the difference equation is solved. The truncation error limits the _accuracy_ of the method. Note the difference between _precision_ and _accuracy_ introducecd here!\n",
    "\n",
    "We can improve the accuracy by taking smaller $h$ for calculating the derivative. Can't we make the answer then arbitrarily exact? Let's try ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors\n",
    "There are two basic sources of error! They have to do with accuracy and with precision.\n",
    "\n",
    "**Accuracy:** How well does the discretized equation represent the original mathematical equation?\n",
    "This is the truncation error. \n",
    "\n",
    "**Precision:** How well is the solution satisfying the discretized equation? This is limited by the roundoff error.\n",
    "\n",
    "### Convergence test\n",
    "In order to determine the accuracy of our solution scheme we study the behaviour of a particular solution scheme under grid (time and/or space) refinement. In our case this means we do a series of runs with decreasing `h`.\n",
    "\n",
    "We use a convenient technique for _vectorizing_ a function which allows to evaluate an arbitrary function for a _parameter vector_. This way of doing it will not help performance. See an example below of how to do true multi-tasking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to vectorize wrap the function to isolate the \n",
    "# variable over which we should loop turn a scalar function \n",
    "# into a vectorized function\n",
    "def hdev(h):\n",
    "    return deriv1(f,1.,h)\n",
    "vhdev = vectorize(hdev)\n",
    "h_pow = range(0,-14,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 10**array(h_pow, dtype=float)\n",
    "figure(2,figsize=(8,8))\n",
    "plot(h_pow, log10(vhdev(h)-2.0),'o')\n",
    "xlim(0,-14), ylabel('log10 (df/dx - 2.0)'), xlabel('log h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reduce the truncation error by taking a smaller interval `h`. However, as you try minimizing the truncation error you will see that there is a limit. At too small `h` the `deriv1` function will try to perform the difference `(f(x+h) - f(x))` with too few or no significant digits and the roundoff error will become larger, and eventually dominate the result. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-processing\n",
    "\n",
    "We saw an example for a case where a particular task needs to be done over and over again with different input parameters. A previous example of this type was the Monte Carlo method. Such problems are called _embarissingly parallel_, essentially because it takes no or very little effort to parallelize them. The following introduces an actual multiprocessing approach that will use multiple of your cpu cores. The work is too small to notice any difference in performance though. You may want to experiment with a task that has more work, and in an environment that has multiple cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(3)\n",
    "h_error = array(p.map(hdev,h))\n",
    "print(h_error)\n",
    "figure(3)\n",
    "plot(h_pow,log10(abs(h_error-2.)),'o')\n",
    "xlim(0,-16), ylabel('$ \\log$ $df/dx - 2.0 $'),xlabel('$\\log h$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary differential equations\n",
    "\n",
    "Differential equations are often hard to solve on paper but in many cases become trivial on a computer. \n",
    "\n",
    "## Euler step\n",
    "Take the simplest, first order ODE\n",
    "$$\n",
    "y^\\prime = f(y,x)\n",
    "$$\n",
    "where the right-hand side (RHS) is the function $f(y,x)$ that specifies the derivative $y^\\prime = \\frac{dy}{dx}$. We are looking for the function $y(x)$, but here not the algebraic expression but the numerical values. For a time dependent problem $x = t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take for example $f (y,x) = 2x$, then we know that $y(x) = x^2$. Let's pretend we do not know the answer, but the initial conditions $y(0) = 0$. How can we numerically calculate $y(x)$ for a series of discrete values $x_i$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]; y.append(0)\n",
    "x=[]; x.append(0)\n",
    "rhs_f = lambda x: 2*x\n",
    "x_thing = x[0]; y_thing = y[0]\n",
    "dx=1.; x_end = 4.\n",
    "while x_thing <= x_end+dx:\n",
    "    y_thing += dx * rhs_f(x_thing)\n",
    "    x_thing += dx\n",
    "    print(x_thing,y_thing)\n",
    "    x.append(x_thing); y.append(y_thing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(4)\n",
    "plot(x,y,'o-',label='numeric')\n",
    "plot(x,array(x)**2,'--',label='analytic')\n",
    "legend();xlabel('$x$'),ylabel('$y(x)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
